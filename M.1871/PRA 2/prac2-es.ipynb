{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#Práctica-2\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Práctica 2</a></div><div class=\"lev2\"><a href=\"#Análisis-del-tráfico-de-la-red\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Análisis del tráfico de la red</a></div><div class=\"lev3\"><a href=\"#Descripción-de-los-datos\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Descripción de los datos</a></div><div class=\"lev1\"><a href=\"#Ejercicios\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Ejercicios</a></div><div class=\"lev2\"><a href=\"#Website-fingerprinting\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span><em>Website fingerprinting</em></a></div><div class=\"lev2\"><a href=\"#Importància-de-les-característiques\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Importancia de las catacterísticas</a></div><div class=\"lev2\"><a href=\"#Avaluación-del-ataque-sobre-Tor\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Avaluación del ataque sobre Tor</a></div><div class=\"lev2\"><a href=\"#Características-del-volumen-del-tráfico\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Características del volumen del tráfico</a></div><div class=\"lev2\"><a href=\"#Efectividad-del-ataque-por-página\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Efectividad del ataque por página</a></div><div class=\"lev2\"><a href=\"#Esquemas-de-padding\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Esquemas de <em>padding</em></a></div><div class=\"lev2\"><a href=\"#Medidas-de-overhead\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span>Medidas de overhead</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "    <div style=\"float: left; width: 50%;\">\n",
    "       <img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "    <p style=\"margin: 0; padding-top: 22px; text-align:right;\">M1.871 · Privacidad</p>\n",
    "    <p style=\"margin: 0; text-align:right;\">Máster Universitario en Ciberseguridad y Privacidad</p>\n",
    "    <p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudios de Informática, Multimedia y Telecomunicación</p>\n",
    "</div>\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"width:100%;\">&nbsp;</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 2\n",
    "\n",
    "---\n",
    "\n",
    "Para resolver esta práctica, tenéis que poner las soluciones en el mismo notebook, en las celdas de código que están en blanco habilitadas para ello. Después de cada celda de código podéis poner una celda markdown en donde podéis justificar vuestra respuesta. No es obligatorio, pero sí muy recomendable que justifiquéis las respuestas que\n",
    "dais, ya que eso facilita la corrección en caso de una respuesta incorrecta (pudiendo valorar el planteamiento), y puede ayudar a descartar posibles sospechas sobre copias.\n",
    "\n",
    "En muchos casos, cuando se pide implementar una función, se proporciona el nombre de la función y los parámetros, indicado como ayuda el tipo de dichos parámetros y el tipo que retorna la función en forma de type hint. Es necesario\n",
    "que respetéis el nombre de la función y, en la medida de los posible, los tipos. Sin embargo podéis implementar el código de la función con total libertad. Podéis definir otras funciones y no respetar del todo los type hints si así lo consideráis oportuno. Dicha indicación sobre la definición de la función aparece comentada para evitar errores de compilación.\n",
    "\n",
    "Este notebook va acompañado de un cuestionario online con preguntas sobre los ejercicios y sobre temas relacionados. Este cuestionario debe ser contestado antes de la fecha de entrega de la práctica. Antes de contestar el cuestionario, tenéis que haber intentado hacer y entender todos los ejercicios.\n",
    "\n",
    "En la carpeta `data` de este repositorio encontraréis conjuntos de datos intermedios en caso de que os quedéis atascados. Estos datos también pueden ser útiles para contestar el cuestionario si no se ha podido acabar o no se ha sabido implementar todos los ejercicios de este notebook.\n",
    "\n",
    "\n",
    "Análisis del tráfico de la red\n",
    "-----------------------------------------------------\n",
    "\n",
    "---\n",
    "\n",
    "Hemos caputrado el tráfico de la red generado por una série de visitas a páginas web. Las páginas seleccionadas son 10 de las páginas más populares según el ranking de [Alexa](https://alexa.com). Cada página ha estado visitada 100 veces con Firefox y 100 veces con el navegador de Tor (una versión modificada de Firefox) a través de la red de Tor. Todas las visitas se hicieron el dia 04-05-2021.\n",
    "\n",
    "Las capturas del tráfico se han procesado para que solo incluyan aquellos paquetes de la red que sean relevantes (el tráfico TCP que ha generado el navegador) y descartar cualquier otro tráfico (p.e., tráfico generado por otras aplicaciones). Además, se han descartado retransmisiones y paquetes TCP vacíos (p.e., ACKs). Finalmente, de cada paquete, extraemos el tamaño de los datos y el _timestamp_ del instante en qué se envió o recibio. El contenido de los datos no es útil para hacer análisis del tráfico ya que está encriptado y suponemos que el atacante es un adversario local y pasivo que no puede desencriptar los datos.\n",
    "\n",
    "\n",
    "### Descripción de los datos\n",
    "\n",
    "Podéis descargar los datos utilizando el siguiente enlace:\n",
    "\n",
    "https://drive.google.com/drive/folders/10hb5Qf3trwX5FZOMFEVHgYaWQverHIng?usp=sharing\n",
    "\n",
    "Tenéis que descomprimir los contenidos de los archivos dentro de la carpeta `data` del repositorio. Los ficheros (una vez descomprimidos) son: `web_traffic.csv` y `tor_traffic.csv`, para el tráfico web y de Tor, respectivamente.\n",
    "\n",
    "Cada fila del fichero corresponde a un único paquete TCP. Las columnas son los siguientes atributos del tráfico:\n",
    "\n",
    "\n",
    " | Nombre | Descripción |\n",
    " | --- | --- |\n",
    " | `website` | El nombre de la página la visita de la cual ha generado el paquete. |\n",
    " | `instance` | El índice de la visita (del 0 al 99). |\n",
    " | `timestamp` | El instante en el que se ha visitado o enviado el paquete. |\n",
    " | `length` | El tamaño de los datos del paquete en bytes. El signo codifica la dirección del paquete: negativo para paquetes recibidos (\"_incoming_\") y positivo para paquetes enviados (\"_outgoing_\"). |\n",
    " \n",
    "Llamamos \"traza\" o \"captura\" a una secuencia de paquetes generados por una visita a una página. El atributo `instance` indexa las trazas de un website (hay 100 visitas por tanto obtenemos 100 trazas). Una traza se identifica de manera única con la tupla (`website`, `instance`) en el dataframe.\n",
    " \n",
    "La lista de las páginas visitadas es:\n",
    "\n",
    "  - bing.com\n",
    "  - wikipedia.org\n",
    "  - nytimes.com\n",
    "  - youtube.com\n",
    "  - amazon.com\n",
    "  - netflix.com\n",
    "  - reddit.com\n",
    "  - vk.com\n",
    "  - twitter.com\n",
    "  - panda.tv\n",
    "\n",
    "Antes de nada carguemos los conjuntos de datos en memoria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# fix numpy's rng seed for reproducibility\n",
    "np.random.seed(0) \n",
    "\n",
    "\n",
    "# shortcut to get website labels from dataframe\n",
    "def labels(df):\n",
    "    return df.index.get_level_values('website')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load web data\n",
    "web = pd.read_csv('data/web_traffic.csv')\n",
    "tor = pd.read_csv('data/tor_traffic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3788997 entries, 0 to 3788996\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   website    object \n",
      " 1   instance   int64  \n",
      " 2   timestamp  float64\n",
      " 3   length     int64  \n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 115.6+ MB\n"
     ]
    }
   ],
   "source": [
    "web.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4262621 entries, 0 to 4262620\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   website    object \n",
      " 1   instance   int64  \n",
      " 2   timestamp  float64\n",
      " 3   length     int64  \n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 130.1+ MB\n"
     ]
    }
   ],
   "source": [
    "tor.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicios\n",
    "\n",
    "## _Website fingerprinting_\n",
    "\n",
    "Para empezar, implementaréis un ataque de _website fingerprinting_ muy sencillo. Como habréis leído en los materiales de la asignatura, un ataque de _website fingerprinting_ considera un adversario que observa el tráfico de la red en un punto intermedio entre el cliente y el servidor web (p.e., un router del proveedor de servicios de Internet). El el caso de Tor, el adversario se encuentra entre el cliente y el primer nodo de la red de Tor, tal com se muestra en la siguiente figura:\n",
    "\n",
    "<img src=\"https://www.ehacking.net/wp-content/uploads/2016/02/fingerprintingtor.jpg\" alt=\"Posició de l'adversari\" style=\"width: 500px;\"><center>Fig. 1. Posició de l'adversari en l'escenari de Tor.</center></img>\n",
    "\n",
    "La mayoría de los ataques de _website fingerprinting_ utilizan clasificadores automáticos para inferir la página que se ha visitado a partir del tráfico encriptado. Los clasificadores toman como *características*, las propiedades del tráfico que son más relevantes y, como *clases*, los nombres de dichas páginas. Por tanto, la aplicación de un ataque en la práctica sigue los siguientes pasos:\n",
    "\n",
    "1. El atacante recoge  datos a través de su navegador. El atacante utiliza el sistema que la víctima utiliza: p.e., si la víctima utiliza Tor, el adversario recoge los datos a través de Tor. Por tanto, los conjunto de datos que os damos corresponden a dos escenarios distintos donde se aplica el ataque.\n",
    "2. Extracción de un conjunto de características del tráfico que sean identificativas de las páginas. Una característica es identificativa si toma valores _diferentes_ para visitas a páginas distintas pero toma valores _parecidos_ para visitas a la misma página.\n",
    "3. Entrenamiento de un clasificador con el conjunto de características junto con las clases a las cuales pertenecen. Los valores de las clases en el conjunto de entrenamiento (es decir, lo nombres de las páginas) también se conocen como \"etiquetas\", ya que representa que el atacante las ha etiquetado en el punto 1.\n",
    "4.Aplicación del clasificador a una traza recogida de la víctima. Se extraen las características otra vez y se utiliza el clasificador para inferir la clase a la que pertenece. En esta práctica, este paso se relizará sobre un conjunto de datos que apartaremos con antelación (conjunto de evaluación) para medir la efectividad del ataque.\n",
    "\n",
    "Podéis encontrar más detalles sobre _website fingerprinting_ en los materiales de la asignatura.\n",
    "\n",
    "**Ejercicio 1** [5%]\n",
    "\n",
    "**a.** [4%] Extraed el siguiente conjunto de características *para cada traza* del conjunto de datos `web`:\n",
    "\n",
    " | Nombre | Descripción |\n",
    " | --- | --- |\n",
    " | `max_in_size` | El tamaño máximo de un paquete recibido. |\n",
    " | `min_in_size` | El tamaño mínimo de un paquete recibido. |\n",
    " | `max_out_size` | El tamaño máximo de un paquete enviado. |\n",
    " | `min_out_size` | El tamaño mínimo de un paquete enviado. |\n",
    " | `mean_in_size` | El tamaño medio de un paquete recibido. |\n",
    " | `mean_out_size` | El tamaño medio de un paquete enviado. |\n",
    "\n",
    "- Haced uso del método `agg` sobre el dataframe para aplicar los métodos de extracción de las características. Ved el siguiente ejemplo que extrae el tamaño máximo de una traza:\n",
    "\n",
    "```py\n",
    "# Group by trace\n",
    "groupby_trace = web.groupby(['website', 'instance'])\n",
    "\n",
    "# Define the feature methods. The syntax is: `\"<feature name>\": (\"<column name>\", <method>)`\n",
    "# That is, apply <method> on the column with name <column name> and name the result as <feature name>\n",
    "feature_methods = {\"max_size\": ('length', lambda x: x.max())}\n",
    "\n",
    "# Apply the methods to extract the features\n",
    "web_features = groupby_trace.agg(**feature_methods)\n",
    "    \n",
    "```\n",
    "\n",
    "De hecho, podríamos haber pasado el método `max` directamente:\n",
    "\n",
    "```py\n",
    "features_methods = {\"max_size\": ('length', max)}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: extract features from the data:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b.** [1%] A continuación tendréis que entrenar un **árbol de decisión** con el conjunto de características que habéis obtenido.\n",
    "\n",
    "Utilizad el módulo de Python `sklearn`. La clase que necesitáis es [`DecisionTreeClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html). En la documentación de `sklearn` encontraréis muchos ejemplos de como entrenar y evaluar un modelo de clasificación. Para tener una visión global sobre el entrenamiento de modelos con `sklearn` podéis consultar el siguiente tutorial:\n",
    "\n",
    "https://scikit-learn.org/stable/tutorial/basic/tutorial.html\n",
    "\n",
    "Nosotros os recomendamos que hagáis uso del método [`cross_val_score`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) de `sklearn` el cual aplica [_k-fold cross-valiation_](https://scikit-learn.org/stable/modules/cross_validation.html). _k-fold cross-validation_ hace múltiples particiones de los conjuntos de datos para entrenar y evaluar el modelo en diferentes muestras de los datos. Por tanto, con _k-fold cross-validation_, se obtienen _mejores_ mediciones del rendimiento del clasificador en la práctica (y, por tanto, del ataque) que si utilizasemos un conjunto fijo de los datos. Los valores de los parámetros que debéis pasar a `cross_val_score` son: \n",
    "\n",
    " | Nombre | Descripción |\n",
    " | --- | --- |\n",
    " | `estimator` | La instancia del clasificador. |\n",
    " | `X` | El conjunto de características sin las etiquetas (nombres de las páginas). Cada fila de `X` corresponde a los valores de las características que hemos extraído de la traza, llamada `instancia` de entrenamiento en el contexto de clasificación.\n",
    " | `y`| El conjunto de etiquetas. La $i$-ésima fila de `y` es el nombre de la página que corresponde a la $i$-ésima instancia de `X`.\n",
    " | `cv` | El número de particiones. Es la $k$ en `k-fold`. Utilizaréis 5 particiones.|\n",
    " | `scoring` | La función para medir el rendimiento del clasificador.  Utilitzad `recall_macro`.|\n",
    " | `random_state`| La semilla del generador de números aleatorios. Fijad-lo a 0. | \n",
    " \n",
    "El [\"_recall_\"](https://en.wikipedia.org/wiki/Precision_and_recall) es la rátio  la ratio de positivos verdaderos y mide la probabilidad de acierto del ataque. Solo es necesario que mostréis la media de la lista de valores que devuelve el método de _cross-validation_.\n",
    " \n",
    "Sea cual sea el método que escogés, recordad fijar la semilla del generador de números aleatorios a `0` utilizando el parámetro `random_state` de los métodos que tienen aleatoriedad (p.e., cuando se instancia la clase `DecisionTreeClassifier`).\n",
    "\n",
    "Podéis utilizar el método `labels` definido en la primera celda de este notebook para extraer las etiquetas del dataframe con las características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: train and test the decision tree with 5-fold cross-validation. Report the mean Recall:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importancia de las características\n",
    "\n",
    "**Ejercicio 2** [5%]\n",
    "\n",
    "El entrenamiento de un árbol de decisión consiste en dividir el conjunto de datos de entrenamiento según los valores de sus características. Estas particiones se calculan maximizando una función que mide la calidad de una partición.\n",
    "\n",
    "Una ventaja de esto es que el orden de una característica en el árbol de decisión se puede interpretar como una medida de la `importancia` relativa de la característica para resolver el problema de clasificación. En nuestro caso: como de efectiva es la característica en distinguir una página a partir de su tráfico.\n",
    "\n",
    "En particular, la característica en el primer nivel del árbol es la característica que se ha utilizado para la primera partición de los datos y que, por tanto, _revela más información_ sobre las páginas.\n",
    "\n",
    "Una vez entrenado, para inferir la clase de una instancia del conjunto de evaluación, se sigue cada nodo del árbol según los valores de sus características hasta llegar a las hojas del árbol, las cuales indican la clase.\n",
    "\n",
    "Utilizad el método de `sklearn`: [`plot_tree`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.plot_tree.html) para visualizar el árbol de decisión. Observad cuales han sido las características más importantes (en los primeros niveles del árbol).\n",
    "\n",
    "Para hacer caber la figura del árbol dentro de la celda, limitad el número de niveles del árbol a tres niveles. Para eso, instanciad un nuevo árbol de clasificación con `max_depth=3` y entrenadlo. Además, podéis modificar el parámetro `font_size` en `plot_tree` y del tamaño de la figura (`figsize`) para acabar de ajustar la figura a la celda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1584x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(22, 10))\n",
    "\n",
    "# TODO: plot a tree with three levels:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaluación del ataque sobre Tor\n",
    "\n",
    "**Ejercicio 3** [10%]\n",
    "\n",
    "**a.** [3%] Extraed las características para los datos de Tor y utilizadlas para entrenar y evaluar un nuevo árbol de decisión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: extract features from tor dataset:\n",
    "\n",
    "# TODO: train and test the decision tree with 5-fold cross-validation. Report the mean Recall:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b.** [7%] A continuación, intentemos averiguar porque el ataque es menos efectivo contra Tor. Mostrad los histogramas del atributo `length`par ambos conjuntos de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot histograms for `tor` and `web` lengths.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Características del volumen del tráfico\n",
    "\n",
    "**Ejercicio 4** [30%]\n",
    "\n",
    "**a.** [15%] Añadid las siguientes características al conjunto de características de los ejercicios anteriores. A continuación, repetid los pasos del ejercicio anterior: extraed las características y entrenad un árbol de decisión.\n",
    "\n",
    "Nuevas características:\n",
    "\n",
    " | Nombre | Descripción |\n",
    " | --- | --- |\n",
    " | `total_in_volume` | El volumen total del tráfico de entrada. Es decir, el número de bytes que se han recibido en total. |\n",
    " | `total_out_volume` | El volumen total del tráfico de salida. |\n",
    " | `packet_count` | El número total de paquetes. |\n",
    " | `load_time` | El tiempo que se ha tardado en cargar la página. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: extract the union of old and new features from the web data:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b.** [5%] Aplicad el ataque de nuevo sobre el nuevo conjunto de características del tráfico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: train and test the decision tree with 5-fold cross-validation. Report the mean Recall:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c.** [5%] Extraed las características de los datos de Tor y aplicad el ataque:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: extract new features from the tor dataset:\n",
    "\n",
    "\n",
    "# TODO: train and test the decision tree with 5-fold cross-validation. Report the mean Recall:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d.** [5%] Mostrad la visualización del nuevo árbol de decisión para ver que característica es la más importante en los datos de Tor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1584x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(22, 10))\n",
    "\n",
    "# TODO: plot the tree:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efectividad del ataque por página\n",
    "\n",
    "**Ejercicio 5** [10%]\n",
    "\n",
    "La efectividad del ataque depende de la página. En este ejercicio debéis aplicar el ataque y mostrar la ratio de positivos verdaderos **por página**.\n",
    "\n",
    "No utilicéis el método `cross_val_score`. Ahora utilizad el método [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) de `sklearn` para dividir los datos entre un conjunto de entrenamiento y otro de evaluación. Entonces, llamad los métodos del clasificador [`fit`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.fit) y [`predict`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.predict) para entrenarlo y obtener las predicciones individuales sobre el conjunto de evaluación, respectivamente. Utilizad las predicciones del clasificador y las etiquetas reales de las instancias del conjunto de evaluación para llamar al método: [`classification_report`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html). Este método devuelve distintas medidas del rendimiento del clasificador (entre ellas el _recall_) por página.\n",
    "\n",
    "Llamad `train_test_split` con los siguientes parámetros:\n",
    "\n",
    "| Nombre | Descripción |\n",
    "| -- | -- |\n",
    "| `X`| Dataframe de les características. |\n",
    "| `train_size`| Ratio del conjunto de entrenamiento respecto al total. Usad 0.75. |\n",
    "| `stratify` | Nos asegura que hay el mismo número de instancias por página en los conjuntos de entrnamiento y de evaluación. Debéis pasar el conjunto de etiquetas que corresponde a `X`. |\n",
    "| `random_state`| Fijad-lo a 0. |\n",
    "\n",
    "Podéis usar el parámetro `output_dict` del método `classification_report` para obtener un diccionario que podéis convertir en un dataframe de la siguiente manera:\n",
    "\n",
    "```py\n",
    "report = classification_report(..., output_dict=True)\n",
    "report pd.DataFrame(report).transpose()\n",
    "display(report)\n",
    "```\n",
    "\n",
    "Las últimas tres filas del report son medidas agregadas que podéis descartar.\n",
    "\n",
    "Por último, calculad la desviación estándard del tiempo de carga de la página y añadidla al report. Utilizad el método del dataframe `sort_values` para ordenar el dataframe según el tiempo de carga y mostrad solo las columnas correspondientes al _recall_ y a la desviación estándard del tiempo de carga.\n",
    "\n",
    "Hacedlo solo para el conjunto de datos de Tor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: obtain train and test splits\n",
    "\n",
    "\n",
    "# TODO: train classifier and predict classes for the test set\n",
    "\n",
    "\n",
    "# TODO: display report\n",
    "\n",
    "\n",
    "# TODO: add and show the load time's stdev next to recall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esquemas de _padding_\n",
    "\n",
    "**Ejercicio 6** [25%]\n",
    "\n",
    "En este ejercicio, debéis implementar y evaluar un esquema de _padding_ del tráfico. El _padding_ se simulará sobre los datos. Es decir, deberéis implementar un método que tome un dataframe y devuelva el dataframe con el _padding_. El esquema es el siguiente:\n",
    " \n",
    " - **_Padding_ al siguiente múltiple**: dado un parámetro $\\alpha$ que indica un número de paquetes fijo, añadimos paquetes a cada traza hasta alcanzar el siguiente múltiplo de $\\alpha$. Por ejemplo, si $\\alpha=200$ y hay 345 paquetes en la traza, debemos añadir 145 paquetes.\n",
    " \n",
    "Como resultado, el esquema crea conjuntos de anonimato respecto a la característica: página que tenían números de paquetes parecidos pasan a tener el mismo número de paquetes. Encontraréis más informació sobre las definiciones de conjunto de anonimato y _padding_ en los materiales de la asignatura.\n",
    "\n",
    "Para las simulaciones haremos las siguientes suposiciones:\n",
    "\n",
    " - Supondremos que también se añade _padding_ a nivel de paquete, de manera que ** todos los paquetes de la traza** acabaran teniendo el mismo tamaño: 1460 bytes.\n",
    " \n",
    " - Los nuevos paquetes que se añaden son paquetes recibidos.\n",
    " \n",
    " - Para simular los tiempos de los paquetes de _padding_, supondremos que los tiempos del _padding_ están distribuidos siguiendo una distribución [`beta`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.beta.html) con los parámetros estimados (con máxima verosimilitud) a partir de los datos:\n",
    "\n",
    "```py\n",
    "# MLE estimate from data\n",
    "delays = tor.timestamp.diff()\n",
    "params = beta.fit(delays.dropna())\n",
    "```\n",
    "\n",
    "Vosotros no tenéis que estimar los parámetros. Os proporcionamos los datos que debéis utilizar para los tiempos en la siguiente celda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import beta\n",
    "\n",
    "\n",
    "PACKET_SIZE      = 1460\n",
    "TIMESTAMP_PARAMS = (0.6961851058342148, 172.0499069713989, 9.536743164062499e-07, 5.721616484081675)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a.** [15%] Implementad los métodos par añadir _padding_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement padding method:    \n",
    "\n",
    "def next_multiple_padding(trace: pd.DataFrame, a: int) -> pd.DataFrame:\n",
    "    \"\"\"Return the padded trace.\"\"\"\n",
    "    # TODO\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b.** [5%] Aplicad el esquema de _padding_ donde $\\alpha$ es el número de paquetes máximo de todas las trazas de Tor **más 1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO: apply padding on Tor traces where `a`is the max num of packets + 1:\n",
    "# Hint: use the apply method on the tortrace groupby.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c.** [4%] Extraed las características y mostrad el dataframe resultante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: extract features and show dataframe:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d.** [1%] Entrenad y evaluad el árbol de decisión con las nuevas características:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: train and test the decision tree classifier with the features from the padded data:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medidas de _overhead_\n",
    "\n",
    "**Ejercicio 7** [15%]\n",
    "\n",
    "Si $X$ es el conjunto de los datos original, $X'$ el conjunt de datos con el _padding_, y $f$ una función que mide una propiedad de los datos (p.e., latencia, volumen). Entonces, definimos el [_overhead_](https://en.wikipedia.org/wiki/Overhead_(computing)) de la siguiente forma:\n",
    "\n",
    "$$\\mbox{Overhead(f, X, X')} = \\frac{f(X')}{f(X)}$$\n",
    "\n",
    "\n",
    "Por ejemplo, si $f$ mide el ancho de banda de la comunicación, la interpretación de _Overhead_(f, X, X') es _cuantas veces más_ ancho de banda se ha utilitzado el el escenario con el _padding_ respecto al escenario sin _padding_.\n",
    "\n",
    "\n",
    "**a.** [10%] Implementad métodos que miden el _overhead_ cuando $f$ mide:\n",
    "\n",
    " 1. El volumen de entrada de la comunicación en bytes.\n",
    " 2. La latencia (tiempo de carga de la página).\n",
    "\n",
    "**Recomendación**: Hacedlo suponiendo que los dataframes que reciben los métodos son los dataframes de las características y no los dataframes con el tráfico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement overhead methods:\n",
    "\n",
    "def overhead_volume(original: pd.DataFrame, padded: pd.DataFrame) -> float:\n",
    "    \"\"\"Return of volume overhead of padded over original.\"\"\"\n",
    "    #TODO\n",
    "    pass\n",
    "\n",
    "\n",
    "def overhead_latency(original: pd.DataFrame, padded: pd.DataFrame) -> float:\n",
    "    \"\"\"Return letency overhead of padded over original.\"\"\"\n",
    "    #TODO\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b.** [5%] Calculad los _overheads_ para el esquema de _padding_ del ejercicio anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: ompute overheads:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "toc": {
   "toc_cell": true,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
